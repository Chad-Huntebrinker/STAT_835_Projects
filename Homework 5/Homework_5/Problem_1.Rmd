---
title: "Problem 2.21"
author: "Chad Huntebrinker"
date: "2025-02-23"
output:
  word_document: default
  html_document: default
---
```{r setup, include=FALSE}
#Load the library for all code chuncks
library("vcdExtra")
data_table <- matrix(c(2, 4, 13, 3,
                       2, 6, 22, 4,
                       0, 1, 15, 8,
                       0, 3, 13, 8), nrow = 4, byrow = TRUE)
rownames(data_table) <- c("<5", "5-15", "15-25", ">25")
colnames(data_table) <- c("Very Dissatisfied", "A Little Satisfied", "Moderately Satisfied", "Very Satisfied")
```
Problem 2.21, we are given a 4x4 matrix with the income (in thousands of dollars) and job satisfaction (in different ranges) for black Americans.

For part A, we need to test the independence of job satisfaction and income using X^2 and interpret and explain the deficiency of this test for these data.  We also need to find the standardized residuals and see if they suggest any association pattern.

```{r echo=FALSE, warning=FALSE}
#Chad Huntebrinker
#Problem 1
#Part a
chi_results <- chisq.test(data_table)

chi_results
chi_results$stdres
```
What we find is the X^2 is about 11.5. For deficiency, the chi-square test assumes that we have large samples to utilize it. However, if we do not, then the test can have unreliable results. A good way to check this is if any of the expected frequency are less than 5.  When we do this, we find a couple of examples (any of the row totals multipled with column 1's total) has an expected frequency less than 5. This leads to the conclusion that we should probably use a small-sample test for this data.

We also see the standardized residuals suggest that as employees get paid more, their satisfaction grows as well.

For part B, we need to conduct a test that treats the variables in a quantitive manner and explain why the results differ so much.

```{r echo=FALSE}
#Part B
income_score <- c(3, 10, 20, 35)
sat_score <- c(1, 3, 4, 5)

cmh_results <- CMHtest(data_table, rscores = income_score, cscores = sat_score)
cat("M^2: ", cmh_results$table[1], "\n")    #M^2
cat("df: ", cmh_results$table[5], "\n")    #df
cat("P-score: ", cmh_results$table[9], "\n")    #P-score
```

The reason why the results differ so much above is because the chi-square test does not take into account ordered categories, it just looks at if there is an association.  The M^2 test statistic, on the other hand, does.

```{r}
#Code Appenix
#Chad Huntebrinker
#Problem 1
#Part a

data_table <- matrix(c(2, 4, 13, 3,
                       2, 6, 22, 4,
                       0, 1, 15, 8,
                       0, 3, 13, 8), nrow = 4, byrow = TRUE)
rownames(data_table) <- c("<5", "5-15", "15-25", ">25")
colnames(data_table) <- c("Very Dissatisfied", "A Little Satisfied", "Moderately Satisfied", "Very Satisfied")

chi_results <- chisq.test(data_table)

chi_results
chi_results$stdres

#The standardized residuals suggest that as employees get paid more, their satisfaction grows as well.

#Part B
income_score <- c(3, 10, 20, 35)
sat_score <- c(1, 3, 4, 5)

cmh_results <- CMHtest(data_table, rscores = income_score, cscores = sat_score)
cat("M^2: ", cmh_results$table[1], "\n")    #M^2
cat("df: ", cmh_results$table[5], "\n")    #df
cat("P-score: ", cmh_results$table[9], "\n")    #P-score

#The chi-square test does not take into account ordered categories, it just looks at if there is
#an association.  The M^2 test statistic does.
```

